# 《机器学习》 周志华

> 这是一份读书笔记，你可以使用`pandoc`转为pdf/epub当做速查速度，如希望深读，非常建议选购[周老师的图书](https://item.jd.com/10717804774.html)

> 书到用时方恨少，绝知此事要躬行

> 阅读笔记中包含了书中习题的解析，仅做参考

## 序言

机器学习从主流为符号学习发展到主流为统计学习，反映了机器学习从理论研究到了应用研究的领域。国内巨著有两篇李航教授的《统计学习方法》以及此书。前者详细的介绍了统计学习方法，本书主要针对机器学习的各个分支。

### 一问： 符号学习是否过时了，统计学习未来何去何从？

机器学习作为学科会螺旋上升逐步进入更高级的形式，从认知到技术应用

### 二问：独立同分布的概率前提是否必要？

从科学研究走出来所面对的便是千变万化的各种场景，不符合概率论前提的问题如何处理，如何实现迁移学习

### 三问：统计学习与深度学习什么关系？

深度学习是基于神经网络，受益于计算能力的提高，可以使用复杂度高的算法来逼近结果的方式，其理论创新所带来的贡献尚不如其名声大噪带动大家的学习激情给机器学习的好处多。

### 四问：机器学习之崛起于数学是否有启发作用？

机器学习只用到了数学中的概率统计部分，已然大放异彩，而对于数学来讲，冰山一角尚都算不上。数学向物理学输出的比较多，向计算机学科转换的较少，是否能够像机器学习一样有更多的学科知识能够成功转向应用领域呢。“抛头露面的是概率和统计，埋头苦干的是代数和逻辑”。然而数学之海洋尚有更多更先进的思想和结论尚未被大家熟知。

### 五问：现在研究机器学习的人是否真的懂数学

符号机器学习时代主要以离线的方法处理问题，统计机器学习时代主要以连续的方法解决问题，这两种方法之间应该没有鸿沟的。

### 六问：大数据时代是否给机器学习带来本质变化

大数据的数据量之变化是否从根本上促使机器学习发生了质变，有哪些机器学习方法会被淘汰，哪些会被发掘出来。

> 以上均为陆汝钤(qián)老师为本书做的序，其中六问发人深省

> 另恭贺陆老师于11.01获”吴文俊人工智能最高成就奖“，实至名归

## 前言

本书难免涉及少量的概率、统计、代数、逻辑等数学知识，简要提及，兴趣自读。总览本书总分三个部分：机器学习的基础知识、经典机器学习方法、进阶学习方法概览。

> 重中之重： 本书草创之初，意旨作为机器学习之入门教材，多从教学角度讨论和记录。机器学习本就是一门不断发展的学科，非几千页难以尽述，未达之处，还需自究。

### 主要符号介绍

博客中不易表述数学代数字符，可以复制去直接使用，当然引入`LaTeX`来书写博客的话，说明你比较仔细，可惜我不太喜欢解决`Y问题`

| 符号 | 释义 |
| :---: | :---: |
| x | 标量 |
| 𝓍 | 标量 |
| X | 变量集 | 
| A | 矩阵 | 
| I | 单位阵 | 
| 𝑋 | 样本空间或状态空间 | 
| 𝒟 | 概率分布 | 
| D | 数据集 | 
| 𝓗 | 假设空间 | 
| H | 假设集 | 
| 𝔏 | 学习算法 | 
| (a,b,c,...) | 行向量 | 
| (a;b;c;...) | 列向量 | 
| (·)^T | 向量转置 | 
| {a,b,c,...} | 集合 | 
| |{a,b,c,...}| | 集合{a,b,c,...}中元素的个数 | 
| P(·) | 概率质量函数 | 
| E[f(·)] | 数学期望 | 
| sup(·) | 上确界 | 
| ‖·‖ | L范数 | 
| ‖(·) | 上确界 | 
| sign(·) | 符号函数 | 

## 一、绪论

### 引言

第一段，周老师有去写网络小说的潜质。

人本身就是一个通过不断学习，减少栽跟头次数的物种，经验老到的人能够根据过往态势成功预测事情的发展方向，趋利避害。

这个过程也交给计算机的话，经验本身便失去了价值，整个社会结构都会发生巨大的变化吧。

基于过往的经验数据构建出可重用的模型，用以预测未来的学科就是机器学习了，是不是很酷。

其中模型就是我们对数据集的抽象，通常来讲

* 模型指全部数据得出来的全局结果
* 模式指局部数据得出来的局部结果

### 基本术语

机器学习并未经过时间的打磨，所以同一个概念有很多说法，估计未来的不久会精简统一许多吧。从计算的角度，我们研究一个事务，首先应该关注输入和输出。

### 假设空间
### 归纳偏好
### 发展历程
### 应用现状
### 阅读材料
### 习题及解析

## 二、模型评估与选择

### 经验误差与过拟合
### 评估方法
### 性能度量
### 比较检验
### 偏差与方差
### 阅读材料

## 三、线性模型

### 基本形式
### 线性回归
### 对数几率回归
### 线性判别分析
### 多分类学习
### 类别不平衡问题
### 阅读材料
### 习题及解析

## 四、决策树

### 基本流程
### 划分选择
### 剪枝处理
### 连续与缺失值
### 多变量决策树
### 阅读材料
### 习题及解析

## 五、神经网络

### 神经元模型
### 感知机与多层网络
### 误差逆传播算法
### 全局最小与局部最小
### 其他常见神经网络
### 深度学习
### 阅读材料
### 习题及解析

## 六、支持向量机

### 间隔与支持向量
### 对偶问题
### 核函数
### 软间隔与正则化
### 支持向量回归
### 核方法
### 阅读材料
### 习题及解析

## 七、贝叶斯分类

### 贝叶斯决策轮
### 极大似然估计
### 朴素贝叶斯分类器
### 半朴素贝叶斯分类器
### 贝叶斯网
### EM算法
### 阅读材料
### 习题及解析

## 八、集成学习

### 个体与集成
### Boosting
### Boosting与随机森林
### 结合策略
### 多样性
### 阅读材料
### 习题及解析

## 九、聚类

### 聚类任务
### 性能度量
### 距离计算
### 原型聚类
### 密度聚类
### 层次聚类
### 阅读材料
### 习题及解析

## 十、降维与度量学习

### k近邻学习
### 低维嵌入
### 主成分分析
### 核化线性降维
### 流形学习
### 度量学习
### 阅读材料
### 习题及解析

## 十一、特征选择与稀疏学习

### 子集搜索与评价
### 过滤式选择
### 包裹式选择
### 嵌入式选择与L正则化
### 稀疏表示与字典学习
### 压缩感知
### 阅读材料
### 习题及解析

## 十二、计算学习理论

### 基础知识
### PAC学习
### 有限假设空间
### VC维
### Randemacher复杂度
### 稳定性
### 阅读材料
### 习题及解析

## 十三、半监督学习

### 未标记样本
### 生成式方法
### 半监督SVM
### 图半监督学习
### 基于分歧的方法
### 半监督聚类
### 阅读材料
### 习题及解析

## 十四、概率图模型

### 隐马尔科夫模型
### 马尔科夫随机场
### 条件随机场
### 学习与推断
### 近似推断
### 话题模型
### 阅读材料
### 习题及解析

## 十五、规则学习

### 基本概念
### 序贯覆盖
### 剪枝优化
### 一阶规划学习
### 归纳逻辑程序设计
### 阅读材料
### 习题及解析

## 十六、强化学习

### 任务与奖赏
### K-摇臂赌博机
### 有模型学习
### 免模型学习
### 值函数近似
### 模仿学习
### 阅读材料
### 习题及解析

## 附录

### 矩阵
### 优化
### 概率分布